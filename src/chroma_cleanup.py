from datetime import datetime, timedelta
import pendulum

import chromadb
from .ollama_embeddings import OllamaEmbeddingFunction

KST = pendulum.timezone("Asia/Seoul")


def parse_kst_datetime(text: str):
    """
    '2026-01-19 11:40:14' -> KST datetime
    """
    try:
        dt = datetime.strptime(text, "%Y-%m-%d %H:%M:%S")
        return dt.replace(tzinfo=KST)
    except Exception:
        return None


def cleanup_old_documents(
    persist_dir: str,
    collection_name: str,
    days: int = 14,
    # Ollama embeddings
    ollama_base_url: str = "http://localhost:11434",
    ollama_embed_model: str = "nomic-embed-text",
):
    client = chromadb.PersistentClient(path=persist_dir)
    ef = OllamaEmbeddingFunction(base_url=ollama_base_url, model=ollama_embed_model)
    col = client.get_collection(collection_name, embedding_function=ef)

    now = datetime.now(tz=KST)
    cutoff = now - timedelta(days=days)

    print(f"ğŸ§¹ ì •ë¦¬ ê¸°ì¤€: {cutoff.strftime('%Y-%m-%d %H:%M:%S %Z')} ì´ì „")

    # idsëŠ” includeì— ë„£ì§€ ì•ŠëŠ”ë‹¤. (ê¸°ë³¸ ë°˜í™˜)
    data = col.get(include=["metadatas"])

    if not data.get("ids"):
        print("ì‚­ì œí•  ë°ì´í„° ì—†ìŒ")
        return 0

    delete_ids = []
    for _id, meta in zip(data["ids"], data.get("metadatas", [])):
        date_str = (meta or {}).get("date", "")
        article_time = parse_kst_datetime(date_str)
        if article_time and article_time < cutoff:
            delete_ids.append(_id)

    if not delete_ids:
        print("ì‚­ì œí•  ì˜¤ë˜ëœ ë¬¸ì„œ ì—†ìŒ")
        return 0

    col.delete(ids=delete_ids)
    try:
        client.persist()
    except Exception:
        pass

    print(f"ì‚­ì œ ì™„ë£Œ: {len(delete_ids)}ê°œ chunk ì œê±°")
    return len(delete_ids)

